<!DOCTYPE html>
<html lang="fr">
  <head>
    <meta charset="UTF-8" />
    <title>Mini démonstrateur RAG (JS + Tailwind + OpenAI)</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <!-- Tailwind CDN -->
    <script src="https://cdn.tailwindcss.com"></script>
  </head>
  <body class="bg-gray-100 min-h-screen">
    <div class="max-w-4xl mx-auto p-4 md:p-8">
      <header class="mb-6">
        <h1 class="text-2xl md:text-3xl font-bold text-gray-900">
          Mini démonstrateur RAG (sans base vectorielle)
        </h1>
        <p class="text-sm text-gray-600 mt-2">
          HTML + Tailwind (CDN) + JavaScript natif + <code>fetch</code> OpenAI ·
          Embeddings en mémoire · Fichiers .txt / .md.
        </p>
        <p class="text-xs text-red-600 mt-1">
          ⚠️ Démonstration uniquement : ta clé OpenAI est exposée dans le
          navigateur. Ne pas utiliser telle quelle en production.
        </p>
      </header>

      <!-- API Key -->
      <section class="bg-white rounded-lg shadow p-4 mb-6">
        <h2 class="font-semibold text-gray-800 mb-2">1. Clé OpenAI</h2>
        <label
          class="block text-sm font-medium text-gray-700 mb-1"
          for="apiKey"
        >
          Clé secrète OpenAI
        </label>
        <input
          id="apiKey"
          type="password"
          class="w-full rounded border-gray-300 text-sm p-2 focus:outline-none focus:ring focus:ring-indigo-500"
          placeholder="sk-..."
        />
        <p class="text-xs text-gray-500 mt-1">
          La clé n'est stockée que côté navigateur (variable JS). Démo
          pédagogique uniquement.
        </p>
      </section>

      <!-- Fichiers & Indexation -->
      <section class="bg-white rounded-lg shadow p-4 mb-6">
        <h2 class="font-semibold text-gray-800 mb-2">
          2. Charger des fichiers pour le RAG
        </h2>
        <p class="text-sm text-gray-600 mb-2">
          Sélectionne quelques fichiers texte ou Markdown contenant ton “corpus
          de connaissance”.
        </p>
        <input
          id="fileInput"
          type="file"
          accept=".txt,.md,.markdown"
          multiple
          class="block w-full text-sm text-gray-700 mb-3"
        />
        <button
          id="indexButton"
          class="inline-flex items-center px-3 py-2 text-sm font-medium rounded bg-indigo-600 text-white hover:bg-indigo-700 disabled:opacity-50 disabled:cursor-not-allowed"
        >
          Indexer les fichiers
        </button>
        <p id="indexStatus" class="text-xs text-gray-600 mt-2"></p>
      </section>

      <!-- Question / Réponse -->
      <section class="bg-white rounded-lg shadow p-4 mb-6">
        <h2 class="font-semibold text-gray-800 mb-2">3. Poser une question</h2>
        <label
          class="block text-sm font-medium text-gray-700 mb-1"
          for="question"
        >
          Question utilisateur
        </label>
        <textarea
          id="question"
          rows="3"
          class="w-full rounded border-gray-300 text-sm p-2 focus:outline-none focus:ring focus:ring-indigo-500"
          placeholder="Pose une question en lien avec les fichiers chargés..."
        ></textarea>
        <button
          id="askButton"
          class="mt-3 inline-flex items-center px-3 py-2 text-sm font-medium rounded bg-emerald-600 text-white hover:bg-emerald-700 disabled:opacity-50 disabled:cursor-not-allowed"
        >
          Répondre avec RAG
        </button>
        <p id="qaStatus" class="text-xs text-gray-600 mt-2"></p>

        <div class="mt-4">
          <h3 class="text-sm font-semibold text-gray-800 mb-1">
            Réponse de l'IA
          </h3>
          <div
            id="answer"
            class="text-sm text-gray-900 bg-gray-50 rounded border border-gray-200 p-3 min-h-[3rem] whitespace-pre-wrap"
          ></div>
        </div>
      </section>

      <!-- Contexte choisi (debug pédagogique) -->
      <section class="bg-white rounded-lg shadow p-4">
        <h2 class="font-semibold text-gray-800 mb-2">
          4. Contexte sélectionné (debug RAG)
        </h2>
        <p class="text-xs text-gray-600 mb-2">
          Ci-dessous, les morceaux de texte les plus proches sémantiquement de
          ta question (calcul de similarité cosinus sur les embeddings).
        </p>
        <div
          id="contextDebug"
          class="text-xs text-gray-800 bg-gray-50 rounded border border-gray-200 p-3 whitespace-pre-wrap max-h-64 overflow-auto"
        ></div>
      </section>
    </div>

    <script>
      // ==========
      // ÉTAT RAG
      // ==========
      const state = {
        apiKey: "",
        // tableaux parallèles : un embedding par chunk
        chunks:
          [] /** @type {Array<{id:number, text:string, fileName:string}>} */,
        embeddings: [] /** @type {Array<number[]>} */,
        nextChunkId: 1,
      };

      // ==========
      // UTILITAIRES
      // ==========

      function $(id) {
        return document.getElementById(id);
      }

      // Coupe le texte en phrases / petits morceaux max ~400 caractères.
      function splitTextIntoChunks(text, maxChars = 400) {
        const cleaned = text.replace(/\r\n/g, "\n").trim();
        if (!cleaned) return [];

        // On découpe d'abord en "paragraphes" grossiers sur double saut de ligne
        const paragraphs = cleaned.split(/\n{2,}/);
        const chunks = [];

        for (const para of paragraphs) {
          const p = para.trim();
          if (!p) continue;

          // On découpe en pseudo-phrases sur la ponctuation forte
          const sentences = p.split(/(?<=[.!?])\s+/);

          let current = "";
          for (let sentence of sentences) {
            sentence = sentence.trim();
            if (!sentence) continue;

            if ((current + " " + sentence).trim().length <= maxChars) {
              current = (current + " " + sentence).trim();
            } else {
              if (current) {
                chunks.push(current);
              }
              // si la phrase est elle-même trop longue, on découpe brutalement
              while (sentence.length > maxChars) {
                chunks.push(sentence.slice(0, maxChars));
                sentence = sentence.slice(maxChars);
              }
              current = sentence;
            }
          }
          if (current) {
            chunks.push(current);
          }
        }
        return chunks;
      }

      // Calcul du cosinus de similarité entre deux vecteurs
      function cosineSimilarity(a, b) {
        let dot = 0;
        let normA = 0;
        let normB = 0;
        const len = Math.min(a.length, b.length);
        for (let i = 0; i < len; i++) {
          dot += a[i] * b[i];
          normA += a[i] * a[i];
          normB += b[i] * b[i];
        }
        if (normA === 0 || normB === 0) return 0;
        return dot / (Math.sqrt(normA) * Math.sqrt(normB));
      }

      // Appel à l'API OpenAI Embeddings via fetch
      async function createEmbedding(text) {
        if (!state.apiKey) {
          throw new Error("Clé OpenAI manquante");
        }
        const response = await fetch("https://api.openai.com/v1/embeddings", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            Authorization: "Bearer " + state.apiKey,
          },
          body: JSON.stringify({
            model: "text-embedding-3-small",
            input: text,
          }),
        });

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(
            "Erreur Embeddings: " + response.status + " - " + errorText
          );
        }

        const data = await response.json();
        console.log("data: ", data);

        return data.data[0].embedding;
      }

      // Appel à l'API Chat Completions (RAG)
      async function askWithContext(question, contextText) {
        if (!state.apiKey) {
          throw new Error("Clé OpenAI manquante");
        }

        const systemPrompt =
          "Tu es un assistant qui répond strictement en français, " +
          "et uniquement à partir du CONTEXTE fourni. " +
          "Si l'information n'est pas dans le contexte, tu dis que tu ne sais pas.";

        const userMessage =
          "CONTEXTE :\n" +
          contextText +
          "\n\nQUESTION UTILISATEUR :\n" +
          question +
          "\n\nRéponds en quelques phrases claires.";

        const response = await fetch(
          "https://api.openai.com/v1/chat/completions",
          {
            method: "POST",
            headers: {
              "Content-Type": "application/json",
              Authorization: "Bearer " + state.apiKey,
            },
            body: JSON.stringify({
              model: "gpt-4o-mini",
              messages: [
                { role: "system", content: systemPrompt },
                { role: "user", content: userMessage },
              ],
            }),
          }
        );

        if (!response.ok) {
          const errorText = await response.text();
          throw new Error(
            "Erreur Chat: " + response.status + " - " + errorText
          );
        }

        const data = await response.json();
        return data.choices[0].message.content;
      }

      // ==========
      // INDEXATION
      // ==========

      async function indexFiles(files) {
        state.chunks = [];
        state.embeddings = [];
        state.nextChunkId = 1;

        const indexStatus = $("indexStatus");
        indexStatus.textContent = "Lecture des fichiers...";

        const fileReadPromises = Array.from(files).map(
          (file) =>
            new Promise((resolve, reject) => {
              const reader = new FileReader();
              reader.onload = () =>
                resolve({
                  fileName: file.name,
                  text: String(reader.result || ""),
                });
              reader.onerror = () =>
                reject(reader.error || new Error("Erreur lecture fichier"));
              reader.readAsText(file, "utf-8");
            })
        );

        const fileContents = await Promise.all(fileReadPromises);

        const allChunks = [];
        for (const { fileName, text } of fileContents) {
          const chunks = splitTextIntoChunks(text);
          for (const c of chunks) {
            allChunks.push({
              id: state.nextChunkId++,
              text: c,
              fileName,
            });
          }
        }

        if (allChunks.length === 0) {
          indexStatus.textContent =
            "Aucun texte exploitable trouvé dans les fichiers.";
          return;
        }

        indexStatus.textContent =
          "Création des embeddings (" + allChunks.length + " chunks)...";

        // Embeddings séquentiels pour la simplicité (demo)
        for (let i = 0; i < allChunks.length; i++) {
          const chunk = allChunks[i];
          indexStatus.textContent =
            "Création des embeddings... " + (i + 1) + " / " + allChunks.length;
          // eslint-disable-next-line no-await-in-loop
          const emb = await createEmbedding(chunk.text);
          state.chunks.push(chunk);
          state.embeddings.push(emb);
        }

        indexStatus.textContent =
          "Indexation terminée. " + state.chunks.length + " morceaux indexés.";
      }

      // ==========
      // RAG : QUESTION
      // ==========

      async function ragAnswer(question) {
        if (!question.trim()) {
          throw new Error("Merci de saisir une question.");
        }
        if (state.chunks.length === 0) {
          throw new Error(
            "Aucun document indexé. Charge des fichiers puis clique sur « Indexer les fichiers »."
          );
        }

        const qaStatus = $("qaStatus");
        qaStatus.textContent = "Création de l'embedding de la question...";
        const queryEmbedding = await createEmbedding(question);

        // Similarités cosinus pour tous les chunks
        const scored = state.chunks.map((chunk, idx) => ({
          chunk,
          score: cosineSimilarity(queryEmbedding, state.embeddings[idx]),
        }));

        scored.sort((a, b) => b.score - a.score);

        const topK = 5;
        const topChunks = scored.slice(0, topK).filter((x) => x.score > 0);

        if (topChunks.length === 0) {
          qaStatus.textContent =
            "Aucun passage pertinent trouvé, mais on interroge tout de même le modèle.";
        } else {
          qaStatus.textContent =
            "Top " +
            topChunks.length +
            " passages sélectionnés (similarité cosinus décroissante).";
        }

        const contextText = topChunks
          .map(
            (x, i) =>
              `[${i + 1}] Fichier: ${x.chunk.fileName} (score=${x.score.toFixed(
                3
              )})\n` + x.chunk.text
          )
          .join("\n\n---\n\n");

        $("contextDebug").textContent =
          contextText || "(pas de contexte sélectionné)";

        qaStatus.textContent += " Appel à OpenAI pour la réponse...";
        const answer = await askWithContext(
          question,
          contextText || "Aucun contexte disponible."
        );

        qaStatus.textContent = "Réponse obtenue.";
        return answer;
      }

      // ==========
      // ÉVÈNEMENTS UI
      // ==========

      window.addEventListener("DOMContentLoaded", () => {
        const apiKeyInput = $("apiKey");
        const indexButton = $("indexButton");
        const askButton = $("askButton");
        const fileInput = $("fileInput");

        apiKeyInput.addEventListener("input", () => {
          state.apiKey = apiKeyInput.value.trim();
        });

        indexButton.addEventListener("click", async () => {
          try {
            const files = fileInput.files;
            if (!files || files.length === 0) {
              $("indexStatus").textContent =
                "Merci de sélectionner au moins un fichier.";
              return;
            }
            if (!state.apiKey) {
              $("indexStatus").textContent =
                "Merci de renseigner d'abord ta clé OpenAI (section 1).";
              return;
            }

            indexButton.disabled = true;
            askButton.disabled = true;
            $("indexStatus").textContent = "Indexation en cours...";
            $("contextDebug").textContent = "";
            $("answer").textContent = "";
            $("qaStatus").textContent = "";

            await indexFiles(files);
          } catch (err) {
            console.error(err);
            $("indexStatus").textContent =
              "Erreur lors de l'indexation : " + err.message;
          } finally {
            indexButton.disabled = false;
            askButton.disabled = false;
          }
        });

        askButton.addEventListener("click", async () => {
          const question = $("question").value;
          if (!state.apiKey) {
            $("qaStatus").textContent =
              "Merci de renseigner d'abord ta clé OpenAI (section 1).";
            return;
          }
          try {
            askButton.disabled = true;
            $("qaStatus").textContent = "Recherche des passages pertinents...";
            $("answer").textContent = "";

            const answer = await ragAnswer(question);
            $("answer").textContent = answer;
          } catch (err) {
            console.error(err);
            $("qaStatus").textContent = "Erreur : " + err.message;
          } finally {
            askButton.disabled = false;
          }
        });
      });
    </script>
  </body>
</html>
